{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST STEPS IN EXPLORING EEG DATA\n",
    "\n",
    "Here we will explore the EEG using the MNE-python package, a python package used for the analysis of EEG and MEG signals.\n",
    "\n",
    "Make sure that the folders containing your data are in the same directory as your Jupyter notebooks and Python scripts. This will make it easier to load in data.\n",
    "\n",
    "If you are using the Jupyter environment on Binder, you can load in the \"python-raw.fif\" EEG data; a file that is small enough to be saved on Github. However, if you are using JupyterLab and Jupyter Notebook via Anaconda or PyCharm, you can load in the \"sub-001_eeg_sub-001_task-think1_eeg.bdf\". The \"*.fif*\" format is the mne-python format, the \"*.bdf*\" is the Biosemi Data Format, the format of the Biosemi EEG acquisition system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Magic command to allow us to interact with figures in Jupyter; only works in Jupyter.\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mne\n",
    "import ipympl\n",
    "import pandas as pd\n",
    "\n",
    "%matplotlib qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Load in an BDF dataset. It should be in the same directory as this script.\n",
    "    We will read in the bdf file using mne input-output module.\n",
    "    This will load in a raw object.\n",
    "    Then plot all channels of the raw data.\n",
    "'''\n",
    "%matplotlib widget\n",
    "fname = 'sub-001_eeg_sub-001_task-think1_eeg.bdf'\n",
    "rawIn = mne.io.read_raw_bdf(fname, preload=True)\n",
    "\n",
    "scale_dict = dict(mag=1e-12, grad=4e-11, eeg=20e-6, eog=150e-6, ecg=5e-4,\n",
    "     emg=1e-3, ref_meg=1e-12, misc=1e-3, stim=1,\n",
    "     resp=1, chpi=1e-4)\n",
    "mne.viz.plot_raw(rawIn, duration=5.0, scalings=scale_dict, remove_dc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    The *.bdf file is quite large and may not work in Binder.\n",
    "    In this case we can load in the *python-raw.fif\" file; *.fif is the mne python format.\n",
    "'''\n",
    "\n",
    "file2read = 'python-raw.fif'   # Define the path to dataset and the dataset title.\n",
    "\n",
    "rawIn = mne.io.read_raw_fif(file2read, preload=True)\n",
    "\n",
    "scale_dict = dict(mag=1e-12, grad=4e-11, eeg=20e-6, eog=150e-6, ecg=5e-4,\n",
    "     emg=1e-3, ref_meg=1e-12, misc=1e-3, stim=1,\n",
    "     resp=1, chpi=1e-4)\n",
    "mne.viz.plot_raw(rawIn, duration=5.0, scalings=scale_dict, remove_dc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The external channels \n",
    "\n",
    "Ext1 and Ext2: HEOG; \n",
    "Ext3 and Ext 4: VEOG (blinks); \n",
    "Ext 7: ECG\n",
    "Ext5: M1\n",
    "Ext6: M2\n",
    "Ext8: FP1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If using the *.bdf file\n",
    "# Set the auxiliary channels to type 'misc' and the stimulus channel to type 'stim'.\n",
    "# This allows each data type to be scaled appropriately when visualized.\n",
    "\n",
    "my_dict={'EXG1': 'eog', 'EXG2': 'eog', 'EXG3': 'eog', 'EXG4': 'eog', 'EXG5': 'eog' , 'EXG6': 'eog', 'EXG7': 'eog', 'EXG8': 'eog',\n",
    "        'GSR1': 'misc', 'GSR2': 'misc', 'Erg1': 'stim', 'Erg2': 'stim', 'Resp': 'resp', 'Plet': 'misc', 'Temp': 'misc', 'Status': 'stim'}\n",
    "print(my_dict)\n",
    "rawIn.set_channel_types(my_dict)\n",
    "\n",
    "mne.viz.plot_raw(rawIn, duration=5.0, scalings=scale_dict, remove_dc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# If using the python-raw.fif file\n",
    "my_dict = {'CB1\"': 'misc', 'CB2\"': 'misc', 'CB1': 'misc', 'CB2': 'misc'}\n",
    "print(my_dict)\n",
    "rawIn.set_channel_types(my_dict)\n",
    "\n",
    "mne.viz.plot_raw(rawIn, duration=5.0, scalings=scale_dict, remove_dc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the data from the raw file and get the dimensions of the data.\n",
    "\n",
    "data1 = rawIn.get_data()     \n",
    "data_dim = data1.shape\n",
    "print(data_dim)\n",
    "print('The number of channels in the current raw dataset is: ', data_dim[0])\n",
    "print('\\nThe number of time samples in the current raw dataset is: ', data_dim[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's take a look at the rawmed1.info attribute, which contains an 'info' object.\n",
    "# This info object is a python dictionary.\n",
    "\n",
    "print(rawIn.info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Let's find the following information from the info object.\n",
    "# - Sampling frequency (Hz)\n",
    "# - Channel labels (electrode names)\n",
    "\n",
    "\n",
    "sfreq = rawIn.info['sfreq']\n",
    "print('The sampling frequency of the current dataset is: ', sfreq)\n",
    "\n",
    "chan_names = rawIn.info['ch_names']\n",
    "print(chan_names)\n",
    "\n",
    "# print out the limit of the lowpass filter applied...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## TASK 1\n",
    "Now that you know the sampling rate of the current raw dataset, you know how many times per second the EEG signal was sampled.\n",
    "You also know the number of time samples of the dataset.\n",
    "With this information, you are going to create the time vector. The time vector shows the time (in seconds) that corresponds to each sample of the data.\n",
    "\n",
    "CLUE: Given that you know the sampling frequency, what is the time step from one sample to the next?\n",
    "      Remember that the sampling frequency tells you how many samples there for every second. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## -----------------------We know the sampling rate of the data, so can we construct the time vector?----------------------\n",
    "'''\n",
    "   Define the sampling frequency (srate) and the number of samples that the time vector should be composed of.\n",
    "   Define the time step.\n",
    "   CLUE: you could use the numpy function, arange: numpy.arange(start, stop, step)\n",
    "'''\n",
    "\n",
    "srate = sfreq               # The sampling frequency.\n",
    "datasize = data_dim[1]      # The number os samples in the time vector.\n",
    "tstep    = 1/srate\n",
    "timev    = np.arange(0, datasize*tstep, tstep)\n",
    "\n",
    "print('The length of the time vector is: ',len(timev))\n",
    "print(f'The duration of the time vector is {timev[-1]}seconds')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now plot a single channel\n",
    "We will plot the Cz channel using the time vector that we just calculated above.\n",
    "We use the *index()* method to get the index of the Cz channel.sfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "''' Now we can plot the data of a single electrode over time.\n",
    "    We want to plot the Cz electrode...\n",
    "'''\n",
    "\n",
    "chanidx = chan_names.index('Cz')             # Find the index of the Cz electrode.\n",
    "plt.plot(timev, data1[chanidx, :])        # Plot the Cz signal\n",
    "plt.xlabel('time (seconds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot an individual channel over a defined time interval\n",
    "Here we will just plot the data of the Pz channel over the 60second to 70second time interval.\n",
    "This means that we need define a shorter time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### But we may want to visualize individual channel data for a pre-defined time interval.\n",
    "\"\"\"Need to consctruct the new time vector\"\"\"\n",
    "lims_sec    = np.array([60, 70])               # We will define the limits of the time interval, from 60seconds to 70seconds\n",
    "lim1, lim2  = (lims_sec * srate).astype(int)   # Find the indices of the start and end of chosen time interval\n",
    "chan2plot   = 'Pz'                             # The index of the channel that you want to plot, here Pz\n",
    "chanindx2   = chan_names.index(chan2plot)\n",
    "RawIn_sel   = data1[chanindx2, lim1:lim2]   # Extract the raw data of interest\n",
    "\n",
    "# Now plot the time interval of data.\n",
    "t = timev[lim1:lim2]                             # We define a new time vector, t, as being between lim1 and lim2\n",
    "plt.plot(t,RawIn_sel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Plot several channels over a defined time interval\n",
    "\n",
    "Here we will plot several channels over a predefined interval.\n",
    "We will plot these channels on the same plot, one above the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chans_sel    = ['C3', 'Cz', 'C4']                                     # Define the channels that you want to plot.\n",
    "chanidx3     = [chan_names.index(item2) for item2 in chans_sel ]      # Find the indices of the channels that you want to plot.\n",
    "\n",
    "data_sel    = data1[chanidx3, lim1:lim2]  # Extract the data for the time interval and electrode of interest.\n",
    "yoffset     = np.array([.001, 0, .001])      # Define a y-offset to seperate the channels\n",
    "y           = data_sel.T + yoffset            # RawIn_sel2.T finds the transpose of the data array - exchange between columns and rows\n",
    "                                            \n",
    "pline = plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude (\\mu_V)')\n",
    "plt.legend(pline, chans_sel)                 # We include a legend to show which signal corresponds to which channel.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's check out the distribution of the EEG over the 60 to 70 second interval for a single electrode.\n",
    "\n",
    "What known distribution does the resulting histogram resemble?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_hist = data1[chanidx3[0], lim1:lim2] \n",
    "plt.hist(data_hist.T, bins='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's carry out a test for Normality or Gaussianity\n",
    "Here we apply a test from the statistics module of the Scipy package.\n",
    "It tests if the data sample has a normal distribution and applies a test from D'Agostino & Pearson (1973). \n",
    "We apply a p-value of .001 and if the returned p-value < .001 then we can accept that the data sample has a normal distribution.\n",
    "\n",
    "You can try plotting the histogram and carrying out the above test on:\n",
    "- a longer time sample \n",
    "- a different time interval \n",
    "- different electrodes\n",
    "\n",
    "Do you observe any differences?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "\n",
    "k2, p = stats.normaltest(data_hist)\n",
    "alpha = 1e-3\n",
    "print(\"p = {:g}\".format(p))\n",
    "if p < alpha:  # null hypothesis: x comes from a normal distribution\n",
    "    print(\"The null hypothesis can be rejected\")\n",
    "    print(\"The data sample comes from a normal distribution\\n\")\n",
    "else:\n",
    "    print(\"The null hypothesis cannot be rejected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now we will plot the EEG again with one little change...\n",
    "\n",
    "mne.viz.plot_raw(rawIn, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE DC OFFSET\n",
    "\n",
    "You notice that none of the electrodes appear to be visible...this is due to what we call the \"**DC Offset**\".\n",
    "The acquisition system works on battery, so DC, and it captures ALL the frequencies including the OHz.\n",
    "The OHz is the offset from zero mean. \n",
    "So we need to remove this offset; after which our signals will have a zero mean.\n",
    "\n",
    "#### There are different ways of removing the DC Offset:\n",
    "\n",
    "We will start by trying to remove the DC offset, by subtracting the mean activity from the activity of one channel.\n",
    "Then we will plot the result.\n",
    "So...\n",
    "- Let's calculate the mean of a few channels.\n",
    "- What do you notice about the means? How do we know that there is a DC offset?\n",
    "\n",
    "Note also the use of the *copy()** method. We use this to make a copy of the original **RawIn** object.\n",
    "When we apply a method such as, *.pick_channels*, to a raw object, we change that object. Therefore, the copy() method is very useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## To test the effect of the DC offset, we will find the mean of a few electrodes.\n",
    "\"\"\"\n",
    "    Find the mean of the data from several channels.\n",
    "    What can we say about the means?\n",
    "\"\"\"\n",
    "\n",
    "raw_temp   = rawIn.copy()                    # Create a copy of the raw object and name it RawIn_temp\n",
    "raw_temp.pick_channels(['F3', 'Fz', 'F4'])     # We are going to compute of a subset of channels.\n",
    "dataIn     = raw_temp.get_data()               # Extract the data from the RawIn object.\n",
    "data_mean  = np.mean(dataIn, 1)                # We want to find the mean over the time samples, so the 2nd dimension.\n",
    "Dmean      = data_mean.tolist()                # Converting the array to a list.\n",
    "\n",
    "print('The mean for each  electrode: {} '.format(Dmean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing the DC Offset\n",
    "\n",
    "So, if we think we need to remove the DC offset, we can do one of the following:\n",
    "- Subtract the mean of each signal from each time sample of each channel.\n",
    "- Carry out high-pass filtering to remove the 0Hz\n",
    "- Carry out **detrending**\n",
    "\n",
    "In the following, you can compare the effect of subtracting the mean and high-pass filtering.\n",
    "We can carry out this test on the **RawIn_sel2** data, that consists of 6 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Subtract the mean\n",
    "# We already know the means of the 6 channels, they are stored in the Dmean list and the data_mean array.\n",
    "# The channel-data of the RawIn_temp object is \"dataIn\"\n",
    "chan_demean1 = np.subtract(dataIn[0,], Dmean[0])\n",
    "chan_demean2 = np.subtract(dataIn[1,], Dmean[1])\n",
    "chan_demean3 = np.subtract(dataIn[2,], Dmean[2])\n",
    "\n",
    "%matplotlib qt\n",
    "## Plot the original and demeaned channels\n",
    "ax1 = plt.subplot(231)\n",
    "ax1.margins(0.5)\n",
    "ax1.plot(timev, dataIn[0,])\n",
    "\n",
    "ax2 = plt.subplot(232)\n",
    "ax2.margins(0.5)\n",
    "ax2.plot(timev,dataIn[1,])\n",
    "\n",
    "ax3 = plt.subplot(233)\n",
    "ax3.margins(0.5)\n",
    "ax3.plot(timev,dataIn[2,])\n",
    "\n",
    "ax4 = plt.subplot(234)\n",
    "ax4.margins(0.5)\n",
    "ax4.plot(timev, chan_demean1)\n",
    "\n",
    "ax5 = plt.subplot(235)\n",
    "ax5.margins(0.5)\n",
    "ax5.plot(timev,chan_demean2)\n",
    "\n",
    "ax6 = plt.subplot(236)\n",
    "ax6.margins(0.5)\n",
    "ax6.plot(timev,chan_demean3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FILTERING THE EEG SIGNAL\n",
    "\n",
    "In EEG, we generally filter to remove high frequency artifacts and low frequency drifts.\n",
    "We can filter our time-domain data, our continuous EEG.\n",
    "We can also filter our spatial-domain data using spatial filters.\n",
    "\n",
    "We begin by filtering our time-domain data:\n",
    "- we apply a high-pass filter to remove low frequency drifts and the DC Offset.\n",
    "- we apply a low-pass filter to remove high frequency artifacts.\n",
    "Here we are going to apply a *high-pass filter* only to try to remove the DC offset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Filter the EEG Signal.\n",
    "#  High-pass filter with limit of 0.1Hz. \n",
    "#  Note that we create a copy of the original rawmed1 object before filtering.\n",
    "\n",
    "rawIn_filt = rawIn.copy().filter(0.1, None, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2:\n",
    "\n",
    "Compare the effect of removing the DC component by demeaning and by filtering for the following set of electrodes:\n",
    "- midline electrodes\n",
    "- frontal electrodes on the left hemisphere.\n",
    "- frontal electrodes on the right hemisphere.\n",
    "\n",
    "Look at the effect of high-pass filtering at 0.5Hz and 1Hz\n",
    "\n",
    "Write your code in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Code for Task 2 goes here.\n",
    "mne.viz.plot_raw(rawIn_filt, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Inspection and Annotation of Data\n",
    "\n",
    "Visually inspect the raw data, **RawIn_ref** by calling **RawIn_ref.plot()\n",
    "\n",
    "Bad channels are color coded gray. By clicking the lines or channel names on the left, you can mark or unmark a bad channel interactively. You can use +/- keys to adjust the scale (also = works for magnifying the data). Note that the initial scaling factors can be set with parameter scalings. If you don’t know the scaling factor for channels, you can automatically set them by passing scalings=’auto’. With pageup/pagedown and home/end keys you can adjust the amount of data viewed at once.\n",
    "\n",
    "You can enter annotation mode by pressing a key. In annotation mode you can mark segments of data (and modify existing annotations) with the left mouse button. You can use the description of any existing annotation or create a new description by typing when the annotation dialog is active. Notice that the description starting with the keyword 'bad' means that the segment will be discarded when epoching the data. Existing annotations can be deleted with the right mouse button. Annotation mode is exited by pressing a again or closing the annotation window.\n",
    "\n",
    "This functionality can bug a bit!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## We will plot our high-pass filtered data.\n",
    "\n",
    "rawIn_filt.plot(duration= 20, start = 60, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### -------------------- PLOT TOPOGRAPHIES FOR DEFINED TIME INTERVAL -------------------------\n",
    "In addition to looking at the signal as a function of time.\n",
    "We can look at the spatial distribution of activity across the head (topography) for a given time interval.\n",
    "We could do this to highlight activity as a specific time or verify if certain activity corresponds to an artifact.\n",
    "The plot a single topography, we need to define a vector of the mean activity over a defined time interval.\n",
    "\n",
    "- Try to find a time interval containing eye-blinks or ECG or alpha oscillation.\n",
    "- Note the time interval or intervals.\n",
    "- Plot the topography of the activity over this time interval.\n",
    "\n",
    "The function to plot topography is given below.\n",
    "You can use the EEG artifact, characteristics CheatSheet to help you detect these artifacts.\n",
    "Note: Before we can visualise the topography, we need to define the electrode layout or **montage** that corresponds\n",
    "to the current data.\n",
    "Here we use the standard 10-20 montage.\n",
    "\n",
    "<img src=\"figures/10-20_1.jpg\" width=520 height=550 /><br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Add the montage information to the current raw object, RawIn.\n",
    "    This is required if you want to plot the topography maps.\n",
    "'''\n",
    "montage = mne.channels.make_standard_montage('standard_1020')               # Assigning the standard 10-20 montage\n",
    "mne.viz.plot_montage(mne.channels.make_standard_montage('standard_1020'))   # Visualize the montage\n",
    "rawIn_filt.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## When we plot the spatial distribution of activity, we pick a time interval of interest \n",
    "#  and plot the mean activity within that time interval. \n",
    "\n",
    "t_int = [70, 75]\n",
    "timeIndx = rawIn_filt.time_as_index(t_int)\n",
    "chan_range = np.arange(0,64)\n",
    "dataseg1 = rawIn_filt.get_data(chan_range, timeIndx[0], timeIndx[1])\n",
    "dataseg_avg = np.mean(dataseg1, 1)\n",
    "\n",
    "fig, ax = plt.subplots(1)\n",
    "mne.viz.plot_topomap(dataseg_avg, rawIn_filt.info, ch_type='eeg', axes=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Now let's plot topographies over several time intervals of interest.\n",
    "\n",
    "time_ints = np.arange(60, 64, 1)                   # Define the time intervals and time step\n",
    "print(time_ints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, len(time_ints)-1, figsize=(15, 5))\n",
    "\n",
    "for ind in range(len(time_ints)-1):\n",
    "    curr_int =  [time_ints[ind], time_ints[ind+1]]\n",
    "    print(curr_int)\n",
    "    timeIndx2 = rawIn_filt.time_as_index(curr_int) \n",
    "    print(timeIndx2)\n",
    "    dataseg_curr  = rawIn_filt.get_data(chan_range, timeIndx2[0], timeIndx2[1])\n",
    "    datamean_curr = np.mean(dataseg_curr, 1)\n",
    "    \n",
    "    mne.viz.plot_topomap(datamean_curr, rawIn_filt.info, ch_type='eeg', axes=axes[ind])\n",
    "    axes[ind].set_title(str(time_ints[ind])+' - '+ str(time_ints[ind+1])+'seconds', {'fontsize' : 20})\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exploring the Spectral & Spectro-Temporal Characteristics of EEG\n",
    "\n",
    "We can also study the EEG signal in terms of its spectral content. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plot the power spectral density over:\n",
    "# - the 1Hz to 80Hz frequency band\n",
    "# - a predefined time interval (60 - 80seconds)\n",
    "\n",
    "%matplotlib widget\n",
    "mne.viz.plot_raw_psd(rawIn_filt, fmin=1, fmax=100, tmin=60, tmax=80, picks='eeg', dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the spectral content over a sub-set of channels\n",
    "\n",
    "Plotting the average topographies for different frequency bands (theta, alpha, beta, gamma).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the topography of activity in different frequency bands.\n",
    "\n",
    "spectra = rawIn_filt.compute_psd(method='multitaper', fmin=0.5, fmax=80, tmin=None, tmax=None, picks='eeg')   # This yields a spectra object.\n",
    "psds, freqs = spectra.get_data(exclude=(), return_freqs=True)\n",
    "print('The frequencies are: ', freqs)\n",
    "\n",
    "# Plot the spectra as a function of frequency.\n",
    "chan_sel = ['Fpz','Fz','FCz','Cz','CPz','Pz']\n",
    "spectra.plot(picks=chan_sel)\n",
    "\n",
    "fbands = {'Theta (4-7Hz)': (4,7), 'Alpha (8-12 Hz)': (8, 12), 'Beta (12-30 Hz)': (12, 30),\n",
    "         'Gamma (30-45 Hz)': (30, 45)}\n",
    "\n",
    "spectra.plot_topomap(bands=fbands, ch_type='eeg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "In the cell below, perform the following:\n",
    "- Load in the dataset \"sub-001_eeg_sub-001_task-think1_eeg.bdf\"\n",
    "- Display the following information onscreen:\n",
    "                - sampling frequency\n",
    "                - number of 'eeg'channels\n",
    "                - the title of the 'eeg' channels\n",
    "                - the number of sample points\n",
    "                - the time resolution of the input data.\n",
    "- In separate plots, plot the average time signal over:\n",
    "                - the midline electrodes\n",
    "                - RH frontal electrodes\n",
    "                - LH frontal electrodes\n",
    "                - RH posterior electrodes\n",
    "                - LH posterior electrodes\n",
    "- Plot the spectrum at three different time intervals: beginning, middle, end of data. \n",
    "                - Do you notice a difference?\n",
    "                - What is the peak frequency?\n",
    "- Plot the topography of alpha-band activity over the same time intervals and compare. \n",
    "\n",
    "- Compare the alpha-band topography over the same time intervals of the datasets, sub-001_eeg_sub-001_task-think1_eeg.bdf and sub-001_eeg_sub-001_task-med2_eeg.bdf. Do you notice any difference?\n",
    "\n",
    "Use the code provided in the example above to help you. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The code for task 3 goes here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Frequency Spectrum of EEG Signals\n",
    "\n",
    "When trying to detect noisy electrodes it is helpful to look at the frequency spectrum of the electrodes.\n",
    "The presence of low frequency or high frequency activity with a lot of energy can indicate a noisy electrode.\n",
    "Below we will plot the **Power Spectral Density (PSD)** for frequencies between 0.5Hz and 40Hz.\n",
    "The power spectral density will be plotted in dB.\n",
    "You can try plotting it again but setting the dB to **False**, can you see a difference?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark the Noisy Channels as \"Bad\"\n",
    "\n",
    "Because activity that corresponds to noise is very often of higher amplitude than the EEG activity that interests us.\n",
    "We can detect bad electrodes by considering:\n",
    "- the time course of the signals.\n",
    "- the frequency spectrum of the signals.\n",
    "It is important to detect these souces of noise so that we can exclude them from our analysis.\n",
    "Here we will mark the noisy channels as **bad** so that we can exclude them from our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4:\n",
    "# Can you find any noisy electrodes that we may need to exclude from our data?\n",
    "# Plot the time course and the frequency spectra of these electrodes to justify your choice.\n",
    "You can do this task in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "   The code for Task 4 can go here.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "        We mark a channel as \"bad\" by adding it to the \"bads\" attribute of \"info\".\n",
    "'''\n",
    "ChanBad = ['Fp1']\n",
    "RawIn_filt.info['bads'] = ChanBad\n",
    "\n",
    "# Plot the PSD again but without the channel marked as \"bad\".\n",
    "mne.viz.plot_raw_psd(RawIn_filt, fmin=0.5, fmax=40, dB=True, exclude='bads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-referencing the EEG:\n",
    "\n",
    "The potential measured in microVolts is measured in relation to the potential at another point, called the reference.\n",
    "\n",
    "This means that the activity at each channel is interpreted relative to the potential at a reference.\n",
    "- the reference can be the mean activity of all electrodes.\n",
    "- the average of the two mastoids (generally these reference channels are marked as Ref1, Ref2 or EXG1, EXG2)\n",
    "The current dataset does not have the external (EXG) channels, so we will apply an average reference.\n",
    "\n",
    "However, we cannot include the bad channels or the VEOG when applying the reference.\n",
    "We use the *pick_types()* method to exclude these channels when applying the average reference.\n",
    "\n",
    "<a href=\"https://predictablynoisy.com/mne-python/generated/mne.set_eeg_reference.html\"> Link to MNE page on **mne.set_eeg.reference()**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Note that we are excluding the eog channel and the bad channels from the average reference calculation.\n",
    "'''\n",
    "RawIn_ref = RawIn_filt.copy().pick_types(eeg=True, exclude= ['bads','eog']).set_eeg_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visual Inspection and Annotation of Data\n",
    "\n",
    "Visually inspect the raw data, **RawIn_ref** by calling **RawIn_ref.plot()\n",
    "\n",
    "Bad channels are color coded gray. By clicking the lines or channel names on the left, you can mark or unmark a bad channel interactively. You can use +/- keys to adjust the scale (also = works for magnifying the data). Note that the initial scaling factors can be set with parameter scalings. If you don’t know the scaling factor for channels, you can automatically set them by passing scalings=’auto’. With pageup/pagedown and home/end keys you can adjust the amount of data viewed at once.\n",
    "\n",
    "You can enter annotation mode by pressing a key. In annotation mode you can mark segments of data (and modify existing annotations) with the left mouse button. You can use the description of any existing annotation or create a new description by typing when the annotation dialog is active. Notice that the description starting with the keyword 'bad' means that the segment will be discarded when epoching the data. Existing annotations can be deleted with the right mouse button. Annotation mode is exited by pressing a again or closing the annotation window.\n",
    "\n",
    "This functionality can bug a bit!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 5:\n",
    "Manually annotate the continuous by marking examples of the following, if you find them:\n",
    "- Eye-blinks\n",
    "- Electrode jumps\n",
    "- Cardiac artifact (ECG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### HERE WE WILL MANUALLY ANNOTATE THE CONTINUOUS DATA TO MARK EYE-BLINKS OR BIG ELECTRODE JUMPS\n",
    "fig = RawIn_ref.plot(block=True)              # Open the interactive raw.plot window. This should open a separate window.\n",
    "fig.canvas.key_press_event('a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Detection of Eye-Blinks\n",
    "In MNE there is a function that automatically identifies eye-blinks.\n",
    "It allows you to segment the data around the eye-blinks identified and then plot the spatial distribution of the activity corresponding to eye-blinks.\n",
    "However, to identify the eye-blinks you need to define a channel on which eye-blinks clearly appear.\n",
    "In the code we have set this channel to be **AF8** but it may not be the best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eogev_elec = 'AF8'                                #Put the label of your selected electrode here...try different electrodes.\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(RawIn_ref, ch_name=eogev_elec, reject_by_annotation=False)\n",
    "eog_epochs.apply_baseline(baseline=(None, -0.2))  # We go from the start of the interval to the -200ms before 0ms\n",
    "eog_epochs.average().plot_joint()\n",
    "eog_epochs.average().plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Detection of ECG (Cardiac activity)\n",
    "In MNE there is a function that automatically identifies cardiac activity (ECG).\n",
    "It allows you to segment the data around the eye-blinks identified and then plot the spatial distribution of the activity corresponding to ECG.\n",
    "However, to identify the cardiac artifacts you need to define a channel on which they clearly appear.\n",
    "Can you identify any channel that clearly displays cardiac artifact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ecg_elec = '';\n",
    "ecg_epochs = mne.preprocessing.create_ecg_epochs(RawIn_ref, ch_name=ecg_elec, reject_by_annotation=False)\n",
    "ecg_epochs.apply_baseline(baseline=(, ))              # Can you suggest a baseline interval for ECG??\n",
    "ecg_epochs.average().plot_joint()\n",
    "ecg_epochs.average().plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting the Continuous Data to look at **Evoked** Activity\n",
    "\n",
    "We have been looking at the continuous data.\n",
    "But, in EEG, we often like to look at the EEG in relation to a stimulus presented during the experiment.\n",
    "We are interested in the activity **evoked** by the stimuli.\n",
    "\n",
    "To study this **evoked** activity, we segment our data around the stimuli used in our study.\n",
    "This means that the chop the data into segments, called **epochs**, by defining a time interval before the stimulus (**baseline**) and a time interval after the stimulus (**post-stimulus interval**).\n",
    "\n",
    "In the example below we will load the *.csv file in which the timing of the stimuli are defined.\n",
    "Then we can this **event** data to our Raw object and the segment the continuous data.\n",
    "\n",
    "***\n",
    "In the data used here, the stimuli are the following:\n",
    "- A Standard Tone\n",
    "- A Novel Tone\n",
    "- A Target Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\n",
    "    './AuditoryOddball_TBI/sub-002/session1/sub-002_ses-01_task-ThreeStimAuditoryOddball_events.csv', sep=';', header=None)\n",
    "annotations = mne.Annotations(event_data[0], event_data[1], event_data[2])\n",
    "RawIn_filt.set_annotations(annotations)\n",
    "events, events_id = mne.events_from_annotations(RawIn_filt)\n",
    "print(events_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "   Segmenting the Continuous Data, we will first segment around all the events.\n",
    "'''\n",
    "\n",
    "tmin, tmax = [ -0.1,1 ]\n",
    "reject_criteria = dict(eeg=40e-6)   # Criterion for epoch rejection\n",
    "event_dict = {'Novel Tone': 1, 'Standard Tone': 2, 'Target Tone': 3}\n",
    "# Call of function to segment the data into epochs.\n",
    "epoch_data = mne.Epochs(RawIn_filt, events, event_id=event_dict, tmin=tmin, tmax=tmax, reject=None, reject_by_annotation=False,\n",
    "                        baseline=(tmin, 0), preload=True,\n",
    "                        detrend=None, verbose=True)\n",
    "\n",
    "fig = mne.viz.plot_events(events, event_id=event_dict, sfreq=RawIn_filt.info['sfreq'],\n",
    "                          first_samp=RawIn_filt.first_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Epoched Data\n",
    "- Here we plot the epoched data of the *Novel Tone* condition only.\n",
    "- The frequency spectrum of the *Novel Tone* activity.\n",
    "- An ERP-image and mean activity for the *Novel Tone* condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "epoch_data['Novel Tone'].plot(events=events, event_id=event_dict, butterfly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_data['Novel Tone'].plot_psd(picks='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_data['Novel Tone'].plot_image(picks='eeg', combine='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Evoked Activity for each condition\n",
    "We calculate the **evoked** activity for each condition (or stimulus) by averaging over all the epochs corresponding to that stimulus.\n",
    "Now we can compare the EEG activity for each experimental condition.\n",
    "\n",
    "**Note:** The results here are not very informative as we are looking at the evoked activity of a single subject.\n",
    "Normally, we calculate the average activity over several participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epochs_novel = epoch_data['Novel Tone']\n",
    "epochs_standard = epoch_data['Standard Tone']\n",
    "\n",
    "# Now we will average over the novel and standard trials. This will give us our evoked activity.\n",
    "evoked_novel = epochs_novel.average()\n",
    "evoked_standard = epochs_standard.average()\n",
    "\n",
    "mne.viz.plot_compare_evokeds(dict(novel=evoked_novel, standard=evoked_standard),\n",
    "                             legend='upper left', show_sensors='upper right')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
