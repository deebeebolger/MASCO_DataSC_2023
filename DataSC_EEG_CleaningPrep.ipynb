{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIRST STEPS IN EXPLORING EEG DATA\n",
    "\n",
    "Now that we have visualized and explored the raw EEG in the temporal, spatial and spectral domains, we will look at the main data cleaning and data preparation techniques used in cognitive science when working with EEG data. \n",
    "\n",
    "In this example, we will use a dataset from the Three-stimulus Auditory Oddball task. \n",
    "This dataset is in a different format to the previous dataset, *.edf* (European Data Format), so we will use a python-based EDF reader to open the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ******* Preparing the data for analysis **********************\n",
    "\n",
    "The following script is an overview of the basic steps applied to prepare the data for analysis.\n",
    "This is called *pre-processing* and involves quite simply cleaning the data. \n",
    "The steps applied here are:\n",
    "- Downsampling\n",
    "- Filtering \n",
    "- Re-referencing\n",
    "- Detecting noisy electrodes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pyedflib\n",
    "import mne\n",
    "import ipympl\n",
    "import pandas as pd\n",
    "\n",
    "sns.set(rc={'figure.figsize':(8, 6)},\n",
    "        font_scale=1.5)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "qt_api = os.environ.get('QT_API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Load in an EDF dataset from the AuditoryOddball_TBI study folder.\n",
    "    We will read in the edf file using the pyedflib package.\n",
    "'''\n",
    "%matplotlib qt   \n",
    "fname = 'sub-004_ses-01_task-ThreeStimAuditoryOddball_eeg.edf'\n",
    "rawmed1 = pyedflib.EdfReader(fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "n = rawmed1.signals_in_file                        # Find the data in the file\n",
    "signal_labels = rawmed1.getSignalLabels()          # Find the channels names\n",
    "print(f'The physical dimension of signal is {rawmed1.getPhysicalDimension(0)}\\n')\n",
    "print(f'The physical maximum of signal is {rawmed1.getPhysicalMaximum(0)}\\n')\n",
    "print(f'The file header: {rawmed1.getHeader()}\\n')\n",
    "print('The signal labels are: ', signal_labels)\n",
    "sigbufs = np.zeros((n, rawmed1.getNSamples()[0]))  # Initialize a sigbuf array to receive the data samples\n",
    "for i in np.arange(n):                             # For each channel add the data to the sigbuf array.\n",
    "    sigbufs[i, :] = rawmed1.readSignal(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TASK 1\n",
    "The sampling rate of the current dataset is 500Hz.\n",
    "This means that the signal is sampled 500 times in each second.\n",
    "Given this information, how can create a time vector that will tell us the time (in seconds) of every sample of data?\n",
    "There is some code included below to help you...\n",
    "\n",
    "First clue: if the sampling frequency is 500Hz, what is the time interval between each sample?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## -----------------------We know the sampling rate of the data, so can we construct the time vector?----------------------\n",
    "srate = rawmed1.getSampleFrequency(0)\n",
    "datasize = sigbufs.shape      # This will give us the size of the sigbufs array:\n",
    "                              # datasize[0] = number of channels datasize[1]= number of samples\n",
    "X = datasize[1]\n",
    "step = 1/srate\n",
    "time = np.arange(0, X*step, step)\n",
    "\n",
    "print(f'The sampling frequency is {srate}Hz\\n')\n",
    "print(f'The dimension of the sigbufs object is {datasize}')\n",
    "print(f'The step in seconds is {step}seconds\\n')\n",
    "print(f'The length of the data in samples is {datasize[1]} samples\\n')\n",
    "print(f'The length of the time vector is: {len(time)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now plot a single channel\n",
    "We will plot the Cz channel using the time vector that we just calculated above.\n",
    "We use the *index()* method to get the index of the Cz channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%matplotlib inline\n",
    "## Now we can plot the data of a single electrode over time.\n",
    "## We want to plot the Cz electrode...\n",
    "chanidx = signal_labels.index('Cz')      # Find the index of the Cz electrode.\n",
    "plt.plot(time,sigbufs[chanidx, :])       # Plot the Cz signal\n",
    "plt.xlabel('time (seconds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot an individual channel over a defined time interval\n",
    "Here we will just plot the data of the Pz channel over the 60second to 70second time interval.\n",
    "This means that we need define a shorter time interval."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### But we may want to visualize individual channel data for a pre-defined time interval.\n",
    "\"\"\"Need to consctruct the new time vector\"\"\"\n",
    "lims_sec    = np.array([60, 70])               # We will define the limits of the time interval, from 60seconds to 70seconds\n",
    "lim1, lim2  = (lims_sec * srate).astype(int)   # Find the indices of the start and end of chosen time interval\n",
    "chan2plot   = 'Pz'                             # The index of the channel that you want to plot\n",
    "chanindx2   = signal_labels.index(chan2plot)\n",
    "RawIn_sel   = sigbufs[chanindx2, lim1:lim2]     # Extract the raw data of interest\n",
    "\n",
    "# Now plot the time interval of data.\n",
    "t = time[lim1:lim2]                             # We define a new time vector, t, as being between lim1 and lim2\n",
    "plt.plot(t,RawIn_sel)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot several channels over a defined time interval\n",
    "\n",
    "Here we will plot several channels over a predefined interval.\n",
    "We will plot these channels on the same plot, one above the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "chans_sel    = ['C3', 'Cz', 'C4']                                     # Define the channels that you want to plot.\n",
    "chanidx3 = [signal_labels.index(item2) for item2 in chans_sel ]       # Find the indices of the channels that you want to plot.\n",
    "\n",
    "RawIn_sel2 = sigbufs[chanidx3, lim1:lim2]   # Extract the data from the\n",
    "yoffset    = np.array([.001, 0, .001])      # Define a y-offset to seperate the channels\n",
    "y          = RawIn_sel2.T + yoffset         # Extract the magnitude data for the selected channel\n",
    "                                            # RawIn_sel2.T finds the transpose of the data array - exchange between columns and rows\n",
    "pline = plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(pline, chans_sel)                 # We include a legend to show which signal corresponds to which channel.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the continuous data into an MNE Raw object.\n",
    "![](figures/mne.png)\n",
    "\n",
    "The Python-MNE package is a very popular package for the processing and analysis of EEG and MEG data.\n",
    "MNE-Python provides many functions to visualize and explore EEG data.\n",
    "\n",
    "We create a what is called in MNE-Python a **Raw object** using the data that we loaded above.\n",
    "To create this Raw object we will need the following information:\n",
    "- the sampling rate (in Hertz) of the data\n",
    "- channel labels\n",
    "- channel types (EEG, EOG, MEG etc.)\n",
    "\n",
    "Of course, to create this raw object and to begin using the MNE functions, we need to have imported mne package.\n",
    "You will notice above that we do not include all the channels when creating the MNE Raw object, we exclude the external channels, EXG1 and EG2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## ---------------- It is much easier to manipulate and visualize the data using the MNE Package -----------------------.\n",
    "\"\"\"\n",
    "    So we will create a simple MNE raw object called RawIn\n",
    "    Initialize an info structure with the following information:\n",
    "    - sampling rate (srate)\n",
    "    - channel labels (signal_labels)\n",
    "    - channel types (eeg) - we need to create this list\n",
    "\"\"\"\n",
    "# Create the channel type list. All channels are type EEG.\n",
    "\n",
    "siglabs   = signal_labels\n",
    "chantypes = ['eeg'] * len(siglabs)\n",
    "sigIn     = sigbufs[0:len(siglabs), :]\n",
    "info = mne.create_info(ch_names=siglabs, ch_types=chantypes, sfreq=srate)\n",
    "RawIn = mne.io.RawArray(sigIn, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unwanted channels and mark channels\n",
    "We will not use the status channel here, so we will drop it.\n",
    "We will define the type of the 'VEOG' channel as an ocular channel (eog).\n",
    "This means that we can distinguish it from the scalp electrodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RawIn.drop_channels('Status')\n",
    "RawIn.set_channel_types({'VEOG': 'eog'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The **Raw object**\n",
    "If you take a look inside the **RawIn** object, you will see that it has different *attributes* such as:\n",
    "- n_times : number of time samples\n",
    "- ch_names : the names of the channels\n",
    "- times : the time vector\n",
    "- an *info* dictionnary with acquisition details such as sampling rate, labels of channels marked as *bad* etc.\n",
    "\n",
    "Below we will access this information and print it to screen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "T = RawIn.times\n",
    "Allchans =  RawIn.info['ch_names']\n",
    "badchans =  RawIn.info['bads']\n",
    "sampfreq =  RawIn.info['sfreq']\n",
    "chtypes  = RawIn.get_channel_types()   # Get the channel types\n",
    "\n",
    "print('The sampling frequency is: ', sampfreq)\n",
    "print('The first 5 channel names are: {}'.format(', '.join(Allchans[:5])))\n",
    "print(f'The channel types are {chtypes}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting All EEG Channels\n",
    "\n",
    "Now we will plot the raw signals of all channels stacked on above the other over time.\n",
    "In the following two cells, we apply two different ways of plotting the EEG signals.\n",
    "\n",
    "Note that **remove_dc** is set to **True** or \"On\". What do you think this means?\n",
    "\n",
    "What might we expect if we set **remove_dc** to **False**?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "##### Visualise all electrode activity #####\n",
    "\n",
    "scale_dict = dict(mag=1e-12, grad=4e-11, eeg=20e-6, eog=150e-6, ecg=5e-4,\n",
    "     emg=1e-3, ref_meg=1e-12, misc=1e-3, stim=1,\n",
    "     resp=1, chpi=1e-4)\n",
    "\n",
    "%matplotlib qt\n",
    "mne.viz.plot_raw(RawIn, events=None, duration=10, start=0, n_channels= 20, scalings='auto', remove_dc=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## We can also plot the data in the RawIn object by using RawIn's '\"plot\" method\n",
    "\n",
    "RawIn.plot(duration= 20, start = 60, scalings=scale_dict, remove_dc=True, )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### WHAT IF WE WANT TO PLOT ONLY A SPECIFIC TIME INTERVAL?\n",
    "\n",
    "In the cell below, you have to plot a single channel, Cz, over the for the 60-70second time window.\n",
    "You first need to construct the time vector.\n",
    "\n",
    "\n",
    "Some help:\n",
    "- You will need to know the sampling frequency (Hz or samples per second) of the data.\n",
    "- The time vector and data vector, corresponding to data from Cz electrode, need to have the same length.\n",
    "- Need to find the index of Cz electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### But we may want to visualize individual channel data for a pre-defined time interval.\n",
    "\"\"\"Need to consctruct the new time vector\"\"\"\n",
    "lims_sec    = np.array([60, 70])\n",
    "lim1, lim2  = (lims_sec * sampfreq).astype(int)   # Find the indices of the start and end of chosen time interval\n",
    "chan_idx    = Allchans.index('Cz')                # The index of the channel that you want to plot\n",
    "RawIn_sel   = RawIn[chan_idx, lim1:lim2]          # Extract the raw data of interest\n",
    "\n",
    "%matplotlib inline\n",
    "t = RawIn_sel[1]                             # Extract the time vector\n",
    "y = RawIn_sel[0].T                           # Extract the magnitude data for the selected channel\n",
    "plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### USE OF RAW METHODS TO GET THE INDICES OF TIME POINTS (IN SECONDS)\n",
    "The Raw method **time_as_index()** can be used to convert a time, in seconds, into an integer index.\n",
    "The times can be presented as a list or an array of times and, in that case, will return an array of indices.\n",
    "\n",
    "In addition, we can also index our Raw object, RawIn, using the channel names rather than the indices.\n",
    "Here we select 3 central channels to plot in a stacked plot.\n",
    "So as to differentiate the signals of each channel, we define an offset for the y axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## Use of the Raw method \"time_as_index\" to find the index\n",
    "Lims = RawIn.time_as_index(lims_sec)\n",
    "list_idx = Lims.tolist()\n",
    "print('The start and end indices of the 60 to 70sec time interval is : ', list_idx)\n",
    "\n",
    "chan_sel    = ['C3', 'Cz', 'C4']                                     # The index of the channel that you want to plot\n",
    "RawIn_sel2 = RawIn[chan_sel, Lims[0]:Lims[1]]\n",
    "yoffset = np.array([.001, 0, .001])\n",
    "t = RawIn_sel2[1]                             # Extract the time vector\n",
    "y = RawIn_sel2[0].T + yoffset                         # Extract the magnitude data for the selected channel\n",
    "pline = plt.plot(t, y)\n",
    "plt.xlabel('Time (seconds)')\n",
    "plt.ylabel('Magnitude')\n",
    "plt.legend(pline, chan_sel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assign a montage to our raw object\n",
    "\n",
    "This is necessary if we want to plot topographies of our data. \n",
    "Here we are using the standard 10-20 system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Add the montage information to the current raw object, RawIn.\n",
    "    This is required if you want to plot the topography maps.\n",
    "'''\n",
    "montage = mne.channels.make_standard_montage('standard_1020')               # Assigning the standard 10-20 montage\n",
    "mne.viz.plot_montage(mne.channels.make_standard_montage('standard_1020'))   # Visualize the montage\n",
    "RawIn.set_montage(montage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## To test the effect of the DC offset, we will find the mean of a few electrodes.\n",
    "\"\"\"\n",
    "    Find the mean of the data from several channels.\n",
    "    What can we say about the means?\n",
    "\"\"\"\n",
    "RawIn_temp = RawIn.copy()                     # Create a copy of the RawIn object and name it RawIn_temp\n",
    "RawIn_temp.pick_channels(['F3', 'Fz', 'F4'])  # We are going to compute of a subset of channels.\n",
    "dataIn    = RawIn_temp.get_data()             # Extract the data from the RawIn object.\n",
    "data_mean = np.mean(dataIn, 1)                # We want to find the mean over the time samples, so the 2nd dimension.\n",
    "Dmean = data_mean.tolist()                    # Converting the array to a list.\n",
    "print('The mean for each  electrode: {} '.format(Dmean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. DOWNSAMPLING\n",
    "\n",
    "Represents the number of times per second that the acquisition system samples the continuous EEG.\n",
    "So, given sampling frequency (or sampling rate) of 1024Hz, this means that the system samples the signal every ______ seconds?\n",
    "\n",
    "The sampling rate has an effect on the analyses that we can carry out on the EEG.\n",
    "For example, if we are interested interested in studying EEG activity around 80Hz, sampling frequency needs to be **at least** twice this frequency of interest - this is the **Nyquist Rule**.\n",
    "\n",
    "However, having a high sampling frequency also implies having a greater volume of data. This can mean longer computing times when we are analysing our data.\n",
    "Generally, in EEG analysis, we are interested in activity in the 0.1Hz to 80Hz frequency band. This means that we do not necessarily need to have a sampling frequency as high as 1024Hz; a sampling frequency of 512Hz or 250Hz will be sufficient to capture the characteristics of the EEG of interest.\n",
    "\n",
    "To reduce the rate at which our EEG is sampled, we can **resample** or **downsample** our data.\n",
    "- How does resampling change the EEG signal?\n",
    "- What other variable is automatically changed when we resample the EEG data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "rsamp = srate/2                                    # Downsample to half of the original sampling frequency.\n",
    "RawIn_rs = RawIn.copy().resample(sfreq=rsamp)      # Create a copy of RawIn and apply downsampling to this copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Filtering\n",
    "\n",
    "In EEG, we generally filter to remove high frequency artifacts and low frequency drifts.\n",
    "We can filter our time-domain data, our continuous EEG.\n",
    "We can also filter our spatial-domain data using spatial filters.\n",
    "\n",
    "We begin by filtering our time-domain data:\n",
    "- we apply a high-pass filter to remove low frequency drifts\n",
    "- we apply a low-pass filter to remove high frequency artifacts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Filter the EEG Signal.\n",
    "#  High-pass filter with limit of 0.1Hz. \n",
    "#  Note that we create a copy of the original rawIn object before filtering.\n",
    "\n",
    "RawIn_hifilt = RawIn.copy().filter(0.1, None, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Filter the EEG Signal\n",
    "#. Low-pass filter with a limit of 40Hz\n",
    "#  Note that we create a copy of the original rawIn object before filtering.\n",
    "\n",
    "RawIn_lofilt = RawIn_hifilt.copy().filter(None, 40, fir_design='firwin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Re-referencing \n",
    "\n",
    "The potential measured in microVolts is measured in relation to the potential at another point, called the reference.\n",
    "\n",
    "This means that the activity at each channel is interpreted relative to the potential at a reference.\n",
    "- the reference can be the mean activity of all electrodes.\n",
    "- the average of the two mastoids (generally these reference channels are marked as Ref1, Ref2 or EXG1, EXG2)\n",
    "The current dataset does not have the external (EXG) channels, so we will apply an average reference.\n",
    "\n",
    "However, we cannot include the bad channels or the VEOG when applying the reference.\n",
    "We use the *pick_types()* method to exclude these channels when applying the average reference.\n",
    "\n",
    "<a href=\"https://predictablynoisy.com/mne-python/generated/mne.set_eeg_reference.html\"> Link to MNE page on **mne.set_eeg.reference()**</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Note that we are excluding the eog channel and the bad channels from the average reference calculation.\n",
    "'''\n",
    "RawIn_ref = RawIn_lofilt.copy().pick_types(eeg=True, exclude= ['bads','misc', 'stim']).set_eeg_reference()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Detecting noisy electrodes \n",
    "\n",
    "Look at the class presentation for an overview of different noise sources in EEG.\n",
    "\n",
    "Different approaches can be taken to identify those electrodes to reject from further analysis:\n",
    "- Manual detection, manual annotation of the data.\n",
    "- Study the spectrum of the data to detect outliers.\n",
    "- Automatic detection of outliers based on measures based on amplitude, the predictability of the signal, the presence of energy in certain frequency bands."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4a. Visual Inspection and Annotation of Data\n",
    "\n",
    "Visually inspect the raw data, **RawIn_ref** by calling **RawIn_ref.plot()\n",
    "\n",
    "Bad channels are color coded gray. By clicking the lines or channel names on the left, you can mark or unmark a bad channel interactively. You can use +/- keys to adjust the scale (also = works for magnifying the data). Note that the initial scaling factors can be set with parameter scalings. If you don’t know the scaling factor for channels, you can automatically set them by passing scalings=’auto’. With pageup/pagedown and home/end keys you can adjust the amount of data viewed at once.\n",
    "\n",
    "You can enter annotation mode by pressing a key. In annotation mode you can mark segments of data (and modify existing annotations) with the left mouse button. You can use the description of any existing annotation or create a new description by typing when the annotation dialog is active. Notice that the description starting with the keyword 'bad' means that the segment will be discarded when epoching the data. Existing annotations can be deleted with the right mouse button. Annotation mode is exited by pressing a again or closing the annotation window.\n",
    "\n",
    "This functionality can bug a bit!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### HERE WE WILL MANUALLY ANNOTATE THE CONTINUOUS DATA TO MARK EYE-BLINKS OR BIG ELECTRODE JUMPS\n",
    "# When you want to annotate a bad section press \"a\"\n",
    "\n",
    "fig = RawIn_ref.plot(block=True)              # Open the interactive raw.plot window. This should open a separate window.\n",
    "fig.canvas.key_press_event('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "'''\n",
    "    Alternatively we can visualize the EEG using the mne.viz routine.\n",
    "'''\n",
    "\n",
    "%matplotlib qt\n",
    "mne.viz.plot_raw(RawIn_ref, events=None, duration=10, start=0, n_channels= 20, scalings='auto', remove_dc=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Task 2:\n",
    "Manually annotate the continuous by marking examples of the following, if you find them:\n",
    "- Eye-blinks\n",
    "- Electrode jumps\n",
    "- Cardiac artifact (ECG)\n",
    "- Muscle artifacts (EMG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "### HERE WE WILL MANUALLY ANNOTATE THE CONTINUOUS DATA TO MARK EYE-BLINKS OR BIG ELECTRODE JUMPS\n",
    "fig = RawIn_ref.plot(block=True, scalings='auto')              # Open the interactive raw.plot window. This should open a separate window.\n",
    "fig.canvas.key_press_event('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## We will plot our data and annotate.\n",
    "%matplotlib qt\n",
    "RawIn_ref.plot(duration= 40, start = 60, scalings='auto', remove_dc=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Frequency Spectrum of EEG Signals\n",
    "\n",
    "When trying to detect noisy electrodes it is helpful to look at the frequency spectrum of the electrodes.\n",
    "The presence of low frequency or high frequency activity with a lot of energy can indicate a noisy electrode.\n",
    "Below we will plot the **Power Spectral Density (PSD)** for frequencies between 0.5Hz and 40Hz.\n",
    "The power spectral density will be plotted in dB.\n",
    "You can try plotting it again but setting the dB to **False**, can you see a difference?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "mne.viz.plot_raw_psd(RawIn_ref, fmin=0.5, fmax=40, dB=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mark the Noisy Channels as \"Bad\"\n",
    "\n",
    "Because activity that corresponds to noise is very often of higher amplitude than the EEG activity that interests us.\n",
    "We can detect bad electrodes by considering:\n",
    "- the time course of the signals.\n",
    "- the frequency spectrum of the signals.\n",
    "It is important to detect these souces of noise so that we can exclude them from our analysis.\n",
    "Here we will mark the noisy channels as **bad** so that we can exclude them from our analysis.\n",
    "\n",
    "Note:\n",
    "When we select a channel during annotation, it will be added as \"bad\" to the info attribute of our data object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "        We mark a channel as \"bad\" by adding it to the \"bads\" attribute of \"info\".\n",
    "'''\n",
    "ChanBad = ['Fp1']\n",
    "RawIn_ref.info['bads'] = ChanBad\n",
    "\n",
    "# Plot the PSD again but without the channel marked as \"bad\".\n",
    "mne.viz.plot_raw_psd(RawIn_ref, fmin=0.5, fmax=40, dB=True, exclude='bads')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3:\n",
    "- Can you find any noisy electrodes that we may need to exclude from our data?\n",
    "- Plot the time course and the frequency spectra of these electrodes to justify your choice.\n",
    "You can do this task in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "   The code for Task 4 can go here.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Detection of Eye-Blinks\n",
    "In MNE there is a function that automatically identifies eye-blinks.\n",
    "It allows you to segment the data around the eye-blinks identified and then plot the spatial distribution of the activity corresponding to eye-blinks.\n",
    "However, to identify the eye-blinks you need to define a channel on which eye-blinks clearly appear.\n",
    "In the code we have set this channel to be **AF8** but it may not be the best choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "eogev_elec = 'AF8'                                #Put the label of your selected electrode here...try different electrodes.\n",
    "eog_epochs = mne.preprocessing.create_eog_epochs(RawIn_ref, ch_name=eogev_elec, reject_by_annotation=False)\n",
    "eog_epochs.apply_baseline(baseline=(None, -0.2))  # We go from the start of the interval to the -200ms before 0ms\n",
    "eog_epochs.average().plot_joint()\n",
    "eog_epochs.average().plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automatic Detection of ECG (Cardiac activity)\n",
    "In MNE there is a function that automatically identifies cardiac activity (ECG).\n",
    "It allows you to segment the data around the eye-blinks identified and then plot the spatial distribution of the activity corresponding to ECG.\n",
    "However, to identify the cardiac artifacts you need to define a channel on which they clearly appear.\n",
    "Can you identify any channel that clearly displays cardiac artifact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "ecg_elec = '';\n",
    "ecg_epochs = mne.preprocessing.create_ecg_epochs(RawIn_ref, ch_name=ecg_elec, reject_by_annotation=False)\n",
    "ecg_epochs.apply_baseline(baseline=(, ))              # Can you suggest a baseline interval for ECG??\n",
    "ecg_epochs.average().plot_joint()\n",
    "ecg_epochs.average().plot_topomap()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot topomaps of Continuous Data\n",
    "Generally, when we plot topomaps of continuous data, we plot the topomaps over a defined interval or, more interesting, we plot the spatial distribution corresponding to different frequency activity in the EEG spectrum.\n",
    "In the example below, we look at the spatial distribution of activity at 10Hz, this corresponds to alpha frequency band.\n",
    "In this example, we calculate the frequency content of the EEG over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib import cm\n",
    "### In continuous data, it is more interesting to look at frequency band activity.\n",
    "refdata = RawIn_ref.get_data()\n",
    "spectra, freqs = mne.time_frequency.psd_array_welch(refdata, srate, fmin=1, fmax=40, n_fft=256, n_overlap=0, n_per_seg=None, \n",
    "                                                        n_jobs=None, average='mean', window='hamming', verbose=None)\n",
    "print(freqs)       # Print the frequencies to screen.\n",
    "\n",
    "# Plot the spectra as a function of frequency.\n",
    "plt.plot(freqs, spectra.T)\n",
    "plt.ylabel(r'PSD ($\\mu$V^2)')\n",
    "\n",
    "## To start with, lets plot the topography of alpha activity (10Hz) across our continuous data.\n",
    "layout = mne.find_layout(RawIn_ref.info, ch_type='eeg', exclude='bads')\n",
    "mne.viz.plot_topomap(spectra[:, 9], RawIn_ref.info, ch_type='eeg', contours=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmenting the Continuous Data to look at **Evoked** Activity\n",
    "\n",
    "We have been looking at the continuous data.\n",
    "But, in EEG, we often like to look at the EEG in relation to a stimulus presented during the experiment.\n",
    "We are interested in the activity **evoked** by the stimuli.\n",
    "\n",
    "To study this **evoked** activity, we segment our data around the stimuli used in our study.\n",
    "This means that the chop the data into segments, called **epochs**, by defining a time interval before the stimulus (**baseline**) and a time interval after the stimulus (**post-stimulus interval**).\n",
    "\n",
    "In the example below we will load the *.csv file in which the timing of the stimuli are defined.\n",
    "Then we can this **event** data to our Raw object and the segment the continuous data.\n",
    "\n",
    "***\n",
    "In the data used here, the stimuli are the following:\n",
    "- A Standard Tone\n",
    "- A Novel Tone\n",
    "- A Target Tone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "event_data = pd.read_csv(\n",
    "    'sub-004_ses-01_task-ThreeStimAuditoryOddball_events.csv', sep=';', header=None)\n",
    "annotations = mne.Annotations(event_data[0], event_data[1], event_data[2])\n",
    "RawIn_ref.set_annotations(annotations)\n",
    "events, events_id = mne.events_from_annotations(RawIn_ref)\n",
    "print(events_id)\n",
    "print(events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "'''\n",
    "   Segmenting the Continuous Data, we will first segment around all the events.\n",
    "'''\n",
    "\n",
    "tmin, tmax = [ -0.1,1 ]\n",
    "reject_criteria = dict(eeg=40e-6)   # Criterion for epoch rejection\n",
    "event_dict = {'Novel Tone': 1, 'Standard Tone': 2, 'Target Tone': 3}\n",
    "# Call of function to segment the data into epochs.\n",
    "epoch_data = mne.Epochs(RawIn_ref, events, event_id=event_dict, tmin=tmin, tmax=tmax, reject=None, reject_by_annotation=False,\n",
    "                        baseline=(tmin, 0), preload=True,\n",
    "                        detrend=None, verbose=True)\n",
    "\n",
    "fig = mne.viz.plot_events(events, event_id=event_dict, sfreq=RawIn_ref.info['sfreq'],\n",
    "                          first_samp=RawIn_ref.first_samp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting Epoched Data\n",
    "- Here we plot the epoched data of the *Novel Tone* condition only.\n",
    "- The frequency spectrum of the *Novel Tone* activity.\n",
    "- An ERP-image and mean activity for the *Novel Tone* condition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib widget\n",
    "epoch_data['Novel Tone'].plot(events=events, event_id=event_dict, scalings='auto', butterfly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_data['Novel Tone'].plot_psd(picks='eeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_data['Novel Tone'].plot_image(picks='eeg', combine='mean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate the Evoked Activity for each condition\n",
    "We calculate the **evoked** activity for each condition (or stimulus) by averaging over all the epochs corresponding to that stimulus.\n",
    "Now we can compare the EEG activity for each experimental condition.\n",
    "\n",
    "**Note:** The results here are not very informative as we are looking at the evoked activity of a single subject.\n",
    "Normally, we calculate the average activity over several participants."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m evoked_novel \u001b[38;5;241m=\u001b[39m epochs_novel\u001b[38;5;241m.\u001b[39maverage()\n\u001b[1;32m      6\u001b[0m evoked_standard \u001b[38;5;241m=\u001b[39m epochs_standard\u001b[38;5;241m.\u001b[39maverage()\n\u001b[0;32m----> 8\u001b[0m \u001b[43mmne\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mviz\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_compare_evokeds\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnovel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevoked_novel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstandard\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevoked_standard\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mlegend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupper left\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_sensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mupper right\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/MASCO_DataSC_2023/venv/lib/python3.9/site-packages/mne/viz/evoked.py:2565\u001b[0m, in \u001b[0;36mplot_compare_evokeds\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   2563\u001b[0m     _draw_colorbar_pce(ax, _colors, _cmap, colorbar_title, colorbar_ticks)\n\u001b[1;32m   2564\u001b[0m \u001b[38;5;66;03m# finish\u001b[39;00m\n\u001b[0;32m-> 2565\u001b[0m \u001b[43mplt_show\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshow\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2566\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [ax\u001b[38;5;241m.\u001b[39mfigure]\n",
      "File \u001b[0;32m~/PycharmProjects/MASCO_DataSC_2023/venv/lib/python3.9/site-packages/mne/viz/utils.py:137\u001b[0m, in \u001b[0;36mplt_show\u001b[0;34m(show, fig, **kwargs)\u001b[0m\n\u001b[1;32m    135\u001b[0m     backend \u001b[38;5;241m=\u001b[39m get_backend()\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m show \u001b[38;5;129;01mand\u001b[39;00m backend \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124magg\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mplt\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/MASCO_DataSC_2023/venv/lib/python3.9/site-packages/matplotlib/pyplot.py:446\u001b[0m, in \u001b[0;36mshow\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    403\u001b[0m \u001b[38;5;124;03mDisplay all open figures.\u001b[39;00m\n\u001b[1;32m    404\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03mexplicitly there.\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m _warn_if_gui_out_of_main_thread()\n\u001b[0;32m--> 446\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_get_backend_mod\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/MASCO_DataSC_2023/venv/lib/python3.9/site-packages/matplotlib/backend_bases.py:3620\u001b[0m, in \u001b[0;36m_Backend.show\u001b[0;34m(cls, block)\u001b[0m\n\u001b[1;32m   3618\u001b[0m     block \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m ipython_pylab \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_interactive()\n\u001b[1;32m   3619\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m block:\n\u001b[0;32m-> 3620\u001b[0m     \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmainloop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PycharmProjects/MASCO_DataSC_2023/venv/lib/python3.9/site-packages/matplotlib/backends/backend_qt.py:605\u001b[0m, in \u001b[0;36mFigureManagerQT.start_main_loop\u001b[0;34m(cls)\u001b[0m\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m qapp:\n\u001b[1;32m    604\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m _maybe_allow_interrupt(qapp):\n\u001b[0;32m--> 605\u001b[0m         qt_compat\u001b[38;5;241m.\u001b[39m_exec(qapp)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.9/lib/python3.9/contextlib.py:124\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/PycharmProjects/MASCO_DataSC_2023/venv/lib/python3.9/site-packages/matplotlib/backends/qt_compat.py:245\u001b[0m, in \u001b[0;36m_maybe_allow_interrupt\u001b[0;34m(qapp)\u001b[0m\n\u001b[1;32m    243\u001b[0m signal\u001b[38;5;241m.\u001b[39msignal(signal\u001b[38;5;241m.\u001b[39mSIGINT, old_sigint_handler)\n\u001b[1;32m    244\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m handler_args \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 245\u001b[0m     \u001b[43mold_sigint_handler\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mhandler_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs_novel = epoch_data['Novel Tone']\n",
    "epochs_standard = epoch_data['Standard Tone']\n",
    "\n",
    "# Now we will average over the novel and standard trials. This will give us our evoked activity.\n",
    "evoked_novel = epochs_novel.average()\n",
    "evoked_standard = epochs_standard.average()\n",
    "\n",
    "mne.viz.plot_compare_evokeds(dict(novel=evoked_novel, standard=evoked_standard),\n",
    "                             legend='upper left', show_sensors='upper right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    },
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "epoch_fname = 'audoddball_epo.fif'\n",
    "evoked_standard.save(epoch_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
